{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (1.97.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: dotenv in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from dotenv) (0.21.0)\n",
      "Requirement already satisfied: dotenv in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /Users/urimchoi/Downloads/anaconda3/lib/python3.12/site-packages (from dotenv) (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install dotenv\n",
    "\n",
    "!pip install dotenv\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AzureOpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load from .env file\n",
    "\n",
    "AZURE_API_KEY = \n",
    "AZURE_ENDPOINT = \n",
    "AZURE_DEPLOYMENT = \"gpt-4o-mini\"\n",
    "AZURE_API_VERSION = \"2025-04-01-preview\"\n",
    "\n",
    "\n",
    "\n",
    "openai = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_ENDPOINT,\n",
    "    api_key=AZURE_API_KEY,\n",
    "    api_version=AZURE_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"BLM_prepost_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of posts sent to GPT\n",
    "posts = df[\"post_body_text\"].dropna().tolist()\n",
    "\n",
    "# Format the post list into a numbered string\n",
    "formatted_posts = \"\\n\".join([f\"{i+1}. {post.strip()}\" for i, post in enumerate(posts)])\n",
    "\n",
    "\n",
    "system_message = {\n",
    "  \"role\": \"system\",\n",
    "  \"content\": \"\"\"\n",
    "You are a leading expert in racial discourse and stereotype analysis. Your task is to analyze each social media post and classify it according to **stereotype-related portrayals of Black individuals**, including Black men, Black women, or Black people/person more generally.\n",
    "\n",
    "Your goal is to evaluate whether the post reinforces, contradicts, or remains neutral toward common **stereotypes about Black people** based on the following **five stereotype dimensions**. Use the examples (both stereotype-aligned and counter-stereotypical) to guide your classification.\n",
    "\n",
    "---\n",
    "\n",
    "**1. Warmth/Hostility (Friendliness / Hostile):**\n",
    "Reflects whether Black individuals are portrayed as kind, emotionally supportive, or caring — versus cold, hostile, or threatening.\n",
    "- **Stereotypical portrayals (Negative valence):** dangerous, criminal, aggressive, quick-to-anger, thug, gangster, sassy\n",
    "- **Counter-stereotypes (Positive valence):** self-sacrificing, nurturing, caring, emotional, gentle, compassionate\n",
    "\n",
    "**2. Capability/Incapability (Competence / Incompetence):**\n",
    "Captures portrayals related to intelligence, independence, or strength — versus incompetence or laziness.\n",
    "- **Stereotypical portrayals (Negative valence):** unintelligent, uneducated, lazy, irresponsible, ignorant, dependent, submissive\n",
    "- **Counter-stereotypes (Positive valence):** strong, athletic, independent, resilient, intelligent, leaders, bold, ambitious\n",
    "\n",
    "**3. Assertiveness (Expressiveness / Attitude):**\n",
    "Describes depictions of Black individuals as confident or outspoken — or framed as having an “attitude” or being overly aggressive.\n",
    "- **Stereotypical portrayals (Negative valence):** loud, have-an-attitude, aggressive, dominant\n",
    "- **Counter-stereotypes (Positive valence):** confident, assertive, proud, articulate, self-assured\n",
    "\n",
    "**4. Status (Class / Respectability):**\n",
    "Focuses on class-based or cultural depictions — including whether someone is seen as respectable or degraded.\n",
    "- **Stereotypical portrayals (Negative valence):** ghetto, unrefined, poor, dirty\n",
    "- **Counter-stereotypes (Positive valence):** cultured, sophisticated, professional, successful, well-dressed\n",
    "\n",
    "**5. Victimhood (Oppression / Harm):**\n",
    "Represents portrayals of Black individuals as victims of systemic or individual harm, violence, or discrimination.\n",
    "- **Negative stereotype alignment:** This dimension is not necessarily negative — it indicates portrayal as oppressed or harmed.\n",
    "- **Examples:** oppressed, violated, attacked, assaulted, discriminated against, targeted, profiled\n",
    "- **Counter-stereotype (positive framing):** protected, defended, supported, vindicated\n",
    "\n",
    "**6. Sexualization (Hypersexualization / Gender Stereotypes):**\n",
    "Captures portrayals that present Black individuals as excessively sexualized or emasculated.\n",
    "- **Stereotypical portrayals (Negative valence):** hypersexual, promiscuous, unfeminine, seductive, emasculating, predatory, jezebel, overly sexual\n",
    "- **Counter-stereotypes (Positive valence):** modest, respectful, loving, demure, emotionally intimate\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "For each social media post, return a JSON object with the following fields:\n",
    "\n",
    "1. **\"clarification\"**: A one-sentence summary of what the post implies about Black individuals.\n",
    "\n",
    "2. **\"dimension\"**: The **most relevant** stereotype dimension:\n",
    "   `\"Warmth/Hostility\"`, `\"Capability/Incapability\"`, `\"Assertiveness\"`, `\"Status\"`, `\"Victimhood\"`, or `\"Sexualization\"`. Only use these 6 dimensions.\n",
    "\n",
    "3. **\"stereotype_term\"** – Identify the word or phrase from the post that reflects the stereotype dimension, either aligning or counteracting with the stereotype dimension.\n",
    "\n",
    "4. **\"valence\"**: A score describing how the stereotype is presented:\n",
    "   - `-1`: Subtle or implicit negative stereotype\n",
    "   - `0`: Neutral or stereotype-irrelevant\n",
    "   - `+1`: Subtle positive or counter-stereotypical portrayal\n",
    "\n",
    "5. **\"group\"**: State the relevant demographic group(s) the post is referring to (“Black men,” “Black women”, \"Black people\", “Black person”, \"Black community\", \"Black family\", \"Female\", \"Male\".).\n",
    "\n",
    "6. **\"stereotype_origin\"** – Based on common stereotype associations in research, identify which group the stereotype term most commonly applies to. (e.g., \"dangerous\" → Black men, \"submissive\" → female)\n",
    "\n",
    "7. **\"rationale\"**: A concise explanation (2–4 sentences) describing:\n",
    "   - Why this dimension was chosen\n",
    "   - How the post reflects the stereotype dimension\n",
    "   - Why this valence score was given\n",
    "   - How the group was identified\n",
    "\n",
    "8. **\"confidence\"**: Your confidence level in this classification:\n",
    "   - `\"uncertain\"` = the post is ambiguous or unclear\n",
    "   - `\"fairly certain\"` = moderately confident in your choice\n",
    "   - `\"very certain\"` = highly confident the classification is accurate\n",
    "\n",
    "Return your response as a JSON list of objects with this format:\n",
    "\n",
    "{\n",
    "  \"post\": \"<original text>\",\n",
    "  \"clarification\": \"<short clarification>\",\n",
    "  \"dimension\": \"<best-matching stereotype dimension>\",\n",
    "  \"stereotype_term\": \"<term or phrase from the post>\",\n",
    "  \"valence\": -1 | 0 | 1,\n",
    "  \"group\": \"<demographic group>\",\n",
    "  \"stereotype_origin\": \"<group stereotype most associated with>\",\n",
    "  \"rationale\": \"<your explanation>\",\n",
    "  \"confidence\": \"unsure\" | \"fairly certain\" | \"very certain\"\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "example_jsons = [\n",
    "  {  # Warmth/Hostility\n",
    "    \"post\": \"Black families are some of the most welcoming and generous people you will ever meet. Treat them with the respect they deserve.\",\n",
    "    \"clarification\": \"The post praises Black families as warm, welcoming, and generous\",\n",
    "    \"dimension\": \"warmth/hostility\",\n",
    "    \"stereotype_term\": \"welcoming\",\n",
    "    \"valence\": 1,\n",
    "    \"group\": \"Black families\",\n",
    "    \"stereotype_origin\": \"Black community\",\n",
    "    \"rationale\": \"By describing Black families as welcoming and generous, the post strongly affirms positive warmth traits while explicitly rejecting negative or hostile stereotypes.\",\n",
    "    \"confidence\": \"very certain\"\n",
    "  },\n",
    "  {  # Warmth/Hostility\n",
    "    \"post\": \"If Black and brown people showed up armed like this, the media would call them dangerous and the police would open fire.\",\n",
    "    \"clarification\": \"The post critiques how Black and brown people are perceived as threatening when armed.\",\n",
    "    \"dimension\": \"warmth/hostility\",\n",
    "    \"stereotype_term\": \"dangerous\",\n",
    "    \"valence\": -1,\n",
    "    \"group\": \"Black people\",\n",
    "    \"stereotype_origin\": \"Black and brown people\",\n",
    "    \"rationale\": \"The post highlights the stereotype of Black and brown people as inherently threatening, revealing a lack of perceived warmth.\",\n",
    "    \"confidence\": \"very certain\"\n",
    "  },\n",
    "\n",
    "  {  # Capability/Incapability\n",
    "    \"post\": \"Lila A. Fenwick, 87, New York City, first black woman to graduate from Harvard Law School.\",\n",
    "    \"clarification\": \"The post highlights a Black woman’s educational achievements.\",\n",
    "    \"dimension\": \"capability/incapability\",\n",
    "    \"stereotype_term\": \"first black woman to graduade from Harvard Law\",\n",
    "    \"valence\": 1,\n",
    "    \"group\": \"Black women\",\n",
    "    \"stereotype_origin\": \"Black women\",\n",
    "    \"rationale\": \"Counters the stereotype of Black women being uneducated by affirming their academic excellence.\",\n",
    "    \"confidence\": \"very certain\"\n",
    "  },\n",
    "  {  # Capability/Incapability\n",
    "    \"post\": \"Black women attorneys are leading the fight against attacks on civil rights.\",\n",
    "    \"clarification\": \"The post highlights Black women lawyers as leaders in defending civil liberties.\",\n",
    "    \"dimension\": \"capability/incapability\",\n",
    "    \"stereotype_term\": \"leading\",\n",
    "    \"valence\": 1,\n",
    "    \"group\": \"Black women\",\n",
    "    \"stereotype_origin\": \"Black women\",\n",
    "    \"rationale\": \"Portrays Black women as competent and effective leaders, reinforcing the capability dimension.\",\n",
    "    \"confidence\": \"very certain\"\n",
    "  },\n",
    "  {  # Assertiveness\n",
    "    \"post\": \"As a fellow Black woman who has run for office, I know how hard campaigning is. Kamala Harris did it with courage, grace, and grit.\",\n",
    "    \"published_date\": \"2020-08-20\",\n",
    "    \"clarification\": \"The post praises Kamala Harris for her leadership and representation.\",\n",
    "    \"dimension\": \"assertiveness\",\n",
    "    \"stereotype_term\": \"courage\",\n",
    "    \"valence\": 1,\n",
    "    \"group\": \"Black women\",\n",
    "    \"stereotype_origin\": \"Black women\",\n",
    "    \"rationale\": \"Highlights leadership, confidence, and persistence, aligning with positive assertiveness.\",\n",
    "    \"confidence\": \"very certain\"\n",
    "  },\n",
    "  {  # Assertiveness\n",
    "    \"post\": \"Black people are saying ‘Geroge floyd's death should be protested until things change.’\",\n",
    "    \"published_date\": \"2020-06-02\",\n",
    "    \"clarification\": \"The post encourages protest as a response to injustice.\",\n",
    "    \"dimension\": \"assertiveness\",\n",
    "    \"stereotype_term\": \"protest\",\n",
    "    \"valence\": 1,\n",
    "    \"group\": \"Black people\",\n",
    "    \"stereotype_origin\": \"Black people\",\n",
    "    \"rationale\": \"Encourages standing up for rights and collective action, reflecting high assertiveness.\",\n",
    "    \"confidence\": \"fairly certain\"\n",
    "  },\n",
    "  {  # Status\n",
    "    \"post\": \"#COVID19 is a deadly crisis that will disproportionately harm Black people due to systemic failures.\",\n",
    "    \"published_date\": \"2020-04-10\",\n",
    "    \"clarification\": \"The post discusses systemic failures harming Black communities during COVID-19.\",\n",
    "    \"dimension\": \"status\",\n",
    "    \"stereotype_term\": \"disproportionately harm\",\n",
    "    \"valence\": -1,\n",
    "    \"group\": \"Black people\",\n",
    "    \"stereotype_origin\": \"Black people\",\n",
    "    \"rationale\": \"Highlights structural inequality and vulnerability, signaling lower societal status.\",\n",
    "    \"confidence\": \"fairly certain\"\n",
    "  },\n",
    "  {  # Status\n",
    "    \"post\": \"Subscribe now to get exclusive access to HBR’s ‘Advancing Black Leaders’ program.\",\n",
    "    \"published_date\": \"2020-03-18\",\n",
    "    \"clarification\": \"Promotes a program to elevate Black professionals into leadership roles.\",\n",
    "    \"dimension\": \"status\",\n",
    "    \"stereotype_term\": \"leaders\",\n",
    "    \"valence\": 1,\n",
    "    \"group\": \"Black people\",\n",
    "    \"stereotype_origin\": \"Black people\",\n",
    "    \"rationale\": \"Affirms leadership and prestige, countering stereotypes of low status.\",\n",
    "    \"confidence\": \"very certain\"\n",
    "  },\n",
    "  {  # Victimhood\n",
    "    \"post\": \"Breonna Taylor was asleep in her bed when police stormed in and killed her. She never had a chance.\",\n",
    "    \"published_date\": \"2020-06-05\",\n",
    "    \"clarification\": \"The post highlights the unjust killing of Breonna Taylor while she was asleep.\",\n",
    "    \"dimension\": \"victimhood\",\n",
    "    \"stereotype_term\": \"never had a chance\",\n",
    "    \"valence\": -1,\n",
    "    \"group\": \"Black women\",\n",
    "    \"stereotype_origin\": \"Black women\",\n",
    "    \"rationale\": \"Depicts a Black woman as an innocent victim of systemic violence, aligning with victimhood.\",\n",
    "    \"confidence\": \"very certain\"\n",
    "  },\n",
    "  {  # Victimhood\n",
    "    \"post\": \"Every Black man in America knows the fear of being pulled over — it could be the last time you see your family.\",\n",
    "    \"published_date\": \"2019-11-31\",\n",
    "    \"clarification\": \"The post underscores the life-threatening risks Black men face during police encounters.\",\n",
    "    \"dimension\": \"victimhood\",\n",
    "    \"stereotype_term\": \"fear of being pulled over\",\n",
    "    \"valence\": -1,\n",
    "    \"group\": \"Black men\",\n",
    "    \"stereotype_origin\": \"Black men\",\n",
    "    \"rationale\": \"Portrays Black men as vulnerable to systemic oppression and danger in everyday situations.\",\n",
    "    \"confidence\": \"very certain\"\n",
    "  },\n",
    "  {  # Sexualization\n",
    "    \"post\": \"R. Eric Thomas writes about growing up as a gay Black teenager and finding love in an unexpected place.\",\n",
    "    \"published_date\": \"2010-01-22\",\n",
    "    \"clarification\": \"A personal story about a gay Black man and his experiences with love.\",\n",
    "    \"dimension\": \"sexualization\",\n",
    "    \"stereotype_term\": \"love\",\n",
    "    \"valence\": 1,\n",
    "    \"group\": \"Black men\",\n",
    "    \"stereotype_origin\": \"Black men\",\n",
    "    \"rationale\": \"Humanizes queer Black male narratives, countering hypersexual or emasculating stereotypes.\",\n",
    "    \"confidence\": \"fairly certain\"\n",
    "  },\n",
    "  {  # Sexualization\n",
    "    \"post\": \"A new study finds that perm hair dyes and relaxers are especially cancer-causing for Black women.\",\n",
    "    \"published_date\": \"2019-12-04\",\n",
    "    \"clarification\": \"Announces health risks tied to beauty products used by Black women.\",\n",
    "    \"dimension\": \"sexualization\",\n",
    "    \"stereotype_term\": \"hair relaxers\",\n",
    "    \"valence\": -1,\n",
    "    \"group\": \"Black women\",\n",
    "    \"stereotype_origin\": \"Black women\",\n",
    "    \"rationale\": \"Connects beauty practices to femininity and desirability norms, tied to sexualized gender expectations.\",\n",
    "    \"confidence\": \"uncertain\"\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def safe_parse_json(output_text, batch_num):\n",
    "    \"\"\"Try to parse JSON output; save raw text if invalid.\"\"\"\n",
    "    try:\n",
    "        return json.loads(output_text)\n",
    "    except json.JSONDecodeError:\n",
    "        match = re.search(r'\\[.*\\]', output_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group())\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"⚠️ Batch {batch_num}: JSON invalid even after repair.\")\n",
    "                with open(f\"batch_{batch_num}_raw.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(output_text)\n",
    "                return []\n",
    "        else:\n",
    "            print(f\"⚠️ Batch {batch_num}: No JSON array found. Raw output saved.\")\n",
    "            with open(f\"batch_{batch_num}_raw.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(output_text)\n",
    "            return []\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def analyze_dataset(df, batch_size=50, output_path=\"BLM_classification_analysis.csv\"):\n",
    "    posts = df[\"post_body_text\"].dropna().tolist()\n",
    "    all_results = []\n",
    "\n",
    "    for start in range(0, len(posts), batch_size):\n",
    "        batch_num = start // batch_size + 1\n",
    "        batch = posts[start:start+batch_size]\n",
    "        formatted_posts = \"\\n\".join([f\"{i+1}. {post.strip()}\" for i, post in enumerate(batch)])\n",
    "\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Here are some examples of how to analyze posts:\\n\\n{json.dumps(example_jsons, indent=2)}\n",
    "\n",
    "Now analyze the following posts:\n",
    "Return ONLY a JSON array with no explanations.\\n\\n{formatted_posts}\"\"\"\n",
    "        }\n",
    "\n",
    "        messages = [system_message, user_message]\n",
    "\n",
    "        for attempt in range(2):\n",
    "            try:\n",
    "                response = openai.chat.completions.create(\n",
    "                    model=AZURE_DEPLOYMENT,  \n",
    "                    messages=messages\n",
    "                )\n",
    "                output_text = response.choices[0].message.content\n",
    "\n",
    "                batch_results = safe_parse_json(output_text, batch_num)\n",
    "\n",
    "                if batch_results:\n",
    "                    all_results.extend(batch_results)\n",
    "\n",
    "                    # Save after each batch (so you don't lose progress)\n",
    "                    pd.DataFrame(all_results).to_csv(output_path, index=False)\n",
    "                    print(f\"✅ Batch {batch_num} saved to {output_path}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error in batch {batch_num}, attempt {attempt+1}: {e}\")\n",
    "                time.sleep(3)\n",
    "        else:\n",
    "            print(f\"❌ Batch {batch_num} failed after 2 attempts.\")\n",
    "\n",
    "    print(f\"\\n✅ Full analysis saved to {output_path}\")\n",
    "    files.download(output_path)\n",
    "    return pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 1 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 2 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 3 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 4: JSON invalid even after repair.\n",
      "⚠️ Batch 4: JSON invalid even after repair.\n",
      "❌ Batch 4 failed after 2 attempts.\n",
      "✅ Batch 5 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 6 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 7 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 8 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 9 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 10 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 11 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 12 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 13 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 14 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 15 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 16 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 17 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 18 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 19: JSON invalid even after repair.\n",
      "⚠️ Batch 19: JSON invalid even after repair.\n",
      "❌ Batch 19 failed after 2 attempts.\n",
      "⚠️ Batch 20: JSON invalid even after repair.\n",
      "✅ Batch 20 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 21 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 22: No JSON array found. Raw output saved.\n",
      "✅ Batch 22 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 23 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 24: JSON invalid even after repair.\n",
      "⚠️ Batch 24: JSON invalid even after repair.\n",
      "❌ Batch 24 failed after 2 attempts.\n",
      "✅ Batch 25 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 26 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 27: JSON invalid even after repair.\n",
      "✅ Batch 27 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 28 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 29: JSON invalid even after repair.\n",
      "✅ Batch 29 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 30 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 31 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 32 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 33 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 34 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 35 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 36 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 37 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 38: No JSON array found. Raw output saved.\n",
      "✅ Batch 38 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 39 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 40 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 41 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 42 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 43 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 44 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 45 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 46 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 47 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 48 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 49: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 49: No JSON array found. Raw output saved.\n",
      "❌ Batch 49 failed after 2 attempts.\n",
      "✅ Batch 50 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 51 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 52 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 53 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 54 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 55 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 56 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 57 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 58 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 59 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 60 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 61 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 62 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 63 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 64 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 65 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 66 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 67: JSON invalid even after repair.\n",
      "⚠️ Batch 67: JSON invalid even after repair.\n",
      "❌ Batch 67 failed after 2 attempts.\n",
      "✅ Batch 68 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 69 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 70 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 71 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 72 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 73 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 74 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 75 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 76 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 77: JSON invalid even after repair.\n",
      "⚠️ Error in batch 77, attempt 2: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "❌ Batch 77 failed after 2 attempts.\n",
      "✅ Batch 78 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 79 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 80: No JSON array found. Raw output saved.\n",
      "✅ Batch 80 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 81: JSON invalid even after repair.\n",
      "⚠️ Batch 81: JSON invalid even after repair.\n",
      "❌ Batch 81 failed after 2 attempts.\n",
      "✅ Batch 82 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 83: JSON invalid even after repair.\n",
      "⚠️ Batch 83: JSON invalid even after repair.\n",
      "❌ Batch 83 failed after 2 attempts.\n",
      "✅ Batch 84 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 85 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 86 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 87 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 88 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 89 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 90: JSON invalid even after repair.\n",
      "⚠️ Batch 90: JSON invalid even after repair.\n",
      "❌ Batch 90 failed after 2 attempts.\n",
      "✅ Batch 91 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 92 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 93 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 94 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 95 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 96 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 97: JSON invalid even after repair.\n",
      "⚠️ Batch 97: JSON invalid even after repair.\n",
      "❌ Batch 97 failed after 2 attempts.\n",
      "✅ Batch 98 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 99 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 100 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 101 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 102 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 103 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 104 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 105 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 106 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 107 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 108 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 109: JSON invalid even after repair.\n",
      "✅ Batch 109 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 110: JSON invalid even after repair.\n",
      "✅ Batch 110 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 111 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 112 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 113 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 114 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 115 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 116 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 117 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 118 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 119 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 120 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 121 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 122 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 123 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 124 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 125 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 126 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 127 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 128 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 129 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 130 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 131 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 132 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 133 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 134 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 135 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 136 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 137 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 138 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 139 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 140: No JSON array found. Raw output saved.\n",
      "✅ Batch 140 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 141 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 142 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 143 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 144 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 145 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 146 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 147 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 148 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 149 saved to BLM_classification_analysis.csv\n",
      "⚠️ Error in batch 150, attempt 1: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "⚠️ Error in batch 150, attempt 2: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "❌ Batch 150 failed after 2 attempts.\n",
      "✅ Batch 151 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 152: JSON invalid even after repair.\n",
      "✅ Batch 152 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 153 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 154 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 155 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 156 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 157: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 157: No JSON array found. Raw output saved.\n",
      "❌ Batch 157 failed after 2 attempts.\n",
      "✅ Batch 158 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 159 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 160 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 161: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 161: No JSON array found. Raw output saved.\n",
      "❌ Batch 161 failed after 2 attempts.\n",
      "✅ Batch 162 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 163 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 164: JSON invalid even after repair.\n",
      "⚠️ Batch 164: JSON invalid even after repair.\n",
      "❌ Batch 164 failed after 2 attempts.\n",
      "✅ Batch 165 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 166 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 167 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 168 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 169: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 169: No JSON array found. Raw output saved.\n",
      "❌ Batch 169 failed after 2 attempts.\n",
      "⚠️ Batch 170: JSON invalid even after repair.\n",
      "⚠️ Batch 170: JSON invalid even after repair.\n",
      "❌ Batch 170 failed after 2 attempts.\n",
      "✅ Batch 171 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 172 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 173 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 174 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 175 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 176 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 177 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 178 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 179 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 180 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 181 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 182 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 183 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 184 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 185 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 186 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 187 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 188 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 189: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 189: No JSON array found. Raw output saved.\n",
      "❌ Batch 189 failed after 2 attempts.\n",
      "✅ Batch 190 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 191 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 192 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 193 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 194: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 194: No JSON array found. Raw output saved.\n",
      "❌ Batch 194 failed after 2 attempts.\n",
      "✅ Batch 195 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 196 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 197 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 198 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 199 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 200: JSON invalid even after repair.\n",
      "✅ Batch 200 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 201 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 202 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 203 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 204 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 205 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 206 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 207 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 208: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 208: No JSON array found. Raw output saved.\n",
      "❌ Batch 208 failed after 2 attempts.\n",
      "✅ Batch 209 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 210 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 211: No JSON array found. Raw output saved.\n",
      "✅ Batch 211 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 212: JSON invalid even after repair.\n",
      "⚠️ Batch 212: JSON invalid even after repair.\n",
      "❌ Batch 212 failed after 2 attempts.\n",
      "✅ Batch 213 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 214 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 215: JSON invalid even after repair.\n",
      "⚠️ Batch 215: JSON invalid even after repair.\n",
      "❌ Batch 215 failed after 2 attempts.\n",
      "✅ Batch 216 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 217 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 218: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 218: No JSON array found. Raw output saved.\n",
      "❌ Batch 218 failed after 2 attempts.\n",
      "✅ Batch 219 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 220 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 221 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 222 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 223 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 224 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 225 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 226 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 227 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 228 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 229 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 230 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 231 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 232 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 233: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 233: No JSON array found. Raw output saved.\n",
      "❌ Batch 233 failed after 2 attempts.\n",
      "✅ Batch 234 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 235 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 236: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 236: JSON invalid even after repair.\n",
      "❌ Batch 236 failed after 2 attempts.\n",
      "⚠️ Error in batch 237, attempt 1: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "⚠️ Batch 237: No JSON array found. Raw output saved.\n",
      "❌ Batch 237 failed after 2 attempts.\n",
      "⚠️ Batch 238: JSON invalid even after repair.\n",
      "✅ Batch 238 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 239 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 240: No JSON array found. Raw output saved.\n",
      "✅ Batch 240 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 241 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 242 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 243: No JSON array found. Raw output saved.\n",
      "✅ Batch 243 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 244 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 245 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 246 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 247: JSON invalid even after repair.\n",
      "⚠️ Batch 247: JSON invalid even after repair.\n",
      "❌ Batch 247 failed after 2 attempts.\n",
      "⚠️ Batch 248: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 248: No JSON array found. Raw output saved.\n",
      "❌ Batch 248 failed after 2 attempts.\n",
      "✅ Batch 249 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 250 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 251: JSON invalid even after repair.\n",
      "✅ Batch 251 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 252 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 253 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 254: JSON invalid even after repair.\n",
      "✅ Batch 254 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 255 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 256: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 256: No JSON array found. Raw output saved.\n",
      "❌ Batch 256 failed after 2 attempts.\n",
      "✅ Batch 257 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 258: No JSON array found. Raw output saved.\n",
      "✅ Batch 258 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 259: JSON invalid even after repair.\n",
      "⚠️ Batch 259: JSON invalid even after repair.\n",
      "❌ Batch 259 failed after 2 attempts.\n",
      "⚠️ Batch 260: JSON invalid even after repair.\n",
      "⚠️ Batch 260: JSON invalid even after repair.\n",
      "❌ Batch 260 failed after 2 attempts.\n",
      "⚠️ Batch 261: JSON invalid even after repair.\n",
      "✅ Batch 261 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 262 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 263: No JSON array found. Raw output saved.\n",
      "✅ Batch 263 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 264 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 265 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 266: JSON invalid even after repair.\n",
      "⚠️ Batch 266: JSON invalid even after repair.\n",
      "❌ Batch 266 failed after 2 attempts.\n",
      "✅ Batch 267 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 268 saved to BLM_classification_analysis.csv\n",
      "⚠️ Error in batch 269, attempt 1: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "⚠️ Error in batch 269, attempt 2: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "❌ Batch 269 failed after 2 attempts.\n",
      "✅ Batch 270 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 271 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 272 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 273 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 274: JSON invalid even after repair.\n",
      "⚠️ Batch 274: JSON invalid even after repair.\n",
      "❌ Batch 274 failed after 2 attempts.\n",
      "✅ Batch 275 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 276 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 277: JSON invalid even after repair.\n",
      "✅ Batch 277 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 278 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 279 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 280 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 281: No JSON array found. Raw output saved.\n",
      "✅ Batch 281 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 282 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 283 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 284: No JSON array found. Raw output saved.\n",
      "✅ Batch 284 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 285 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 286 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 287 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 288 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 289 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 290 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 291 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 292 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 293 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 294 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 295 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 296 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 297: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 297: No JSON array found. Raw output saved.\n",
      "❌ Batch 297 failed after 2 attempts.\n",
      "✅ Batch 298 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 299 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 300 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 301 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 302 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 303 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 304 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 305: No JSON array found. Raw output saved.\n",
      "✅ Batch 305 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 306: No JSON array found. Raw output saved.\n",
      "✅ Batch 306 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 307 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 308 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 309: No JSON array found. Raw output saved.\n",
      "✅ Batch 309 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 310 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 311 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 312 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 313 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 314 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 315 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 316 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 317 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 318 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 319 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 320 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 321: JSON invalid even after repair.\n",
      "✅ Batch 321 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 322 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 323 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 324 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 325 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 326 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 327 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 328 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 329 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 330 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 331 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 332 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 333 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 334 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 335 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 336 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 337 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 338: No JSON array found. Raw output saved.\n",
      "✅ Batch 338 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 339 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 340 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 341 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 342: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 342: No JSON array found. Raw output saved.\n",
      "❌ Batch 342 failed after 2 attempts.\n",
      "✅ Batch 343 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 344 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 345 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 346 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 347 saved to BLM_classification_analysis.csv\n",
      "⚠️ Error in batch 348, attempt 1: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "✅ Batch 348 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 349 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 350 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 351 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 352 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 353 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 354 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 355 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 356 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 357 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 358 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 359 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 360 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 361 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 362 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 363 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 364: No JSON array found. Raw output saved.\n",
      "✅ Batch 364 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 365: JSON invalid even after repair.\n",
      "✅ Batch 365 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 366 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 367 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 368 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 369 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 370 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 371 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 372 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 373 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 374 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 375 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 376 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 377 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 378 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 379 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 380 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 381 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 382 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 383 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 384 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 385 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 386 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 387 saved to BLM_classification_analysis.csv\n",
      "⚠️ Error in batch 388, attempt 1: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "⚠️ Error in batch 388, attempt 2: the JSON object must be str, bytes or bytearray, not NoneType\n",
      "❌ Batch 388 failed after 2 attempts.\n",
      "✅ Batch 389 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 390 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 391 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 392 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 393 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 394: JSON invalid even after repair.\n",
      "⚠️ Batch 394: No JSON array found. Raw output saved.\n",
      "❌ Batch 394 failed after 2 attempts.\n",
      "✅ Batch 395 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 396 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 397 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 398 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 399 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 400 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 401 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 402 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 403 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 404 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 405 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 406 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 407 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 408 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 409 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 410: JSON invalid even after repair.\n",
      "✅ Batch 410 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 411 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 412: JSON invalid even after repair.\n",
      "✅ Batch 412 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 413 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 414: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 414: No JSON array found. Raw output saved.\n",
      "❌ Batch 414 failed after 2 attempts.\n",
      "⚠️ Batch 415: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 415: No JSON array found. Raw output saved.\n",
      "❌ Batch 415 failed after 2 attempts.\n",
      "✅ Batch 416 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 417 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 418 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 419 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 420 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 421 saved to BLM_classification_analysis.csv\n",
      "✅ Batch 422 saved to BLM_classification_analysis.csv\n",
      "⚠️ Batch 423: No JSON array found. Raw output saved.\n",
      "⚠️ Batch 423: No JSON array found. Raw output saved.\n",
      "❌ Batch 423 failed after 2 attempts.\n",
      "✅ Batch 424 saved to BLM_classification_analysis.csv\n",
      "\n",
      "✅ Full analysis saved to BLM_classification_analysis.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_results \u001b[38;5;241m=\u001b[39m analyze_dataset(df, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 73\u001b[0m, in \u001b[0;36manalyze_dataset\u001b[0;34m(df, batch_size, output_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed after 2 attempts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Full analysis saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(output_path)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "df_results = analyze_dataset(df, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matching complete. File saved: BLM_classification_with_dates_fuzzy.csv\n"
     ]
    }
   ],
   "source": [
    "# Adding dates through merging and matching post text \n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "\n",
    "classification_df = pd.read_csv(\"BLM_classification_analysis.csv\")\n",
    "prepost_df = pd.read_csv(\"BLM_prepost_final.csv\")\n",
    "\n",
    "\n",
    "post_to_date = dict(zip(prepost_df[\"post_body_text\"], prepost_df[\"published_at\"]))\n",
    "\n",
    "# List of all post_body_text values for matching\n",
    "post_list = list(prepost_df[\"post_body_text\"])\n",
    "\n",
    "matched_dates = []\n",
    "match_scores = []\n",
    "\n",
    "# Loop through each classification post and find closest match\n",
    "for post in classification_df[\"post\"]:\n",
    "    if pd.isna(post) or not isinstance(post, str):\n",
    "        matched_dates.append(None)\n",
    "        match_scores.append(None)\n",
    "        continue\n",
    "\n",
    "    match, score, _ = process.extractOne(\n",
    "        post, post_list, scorer=fuzz.token_sort_ratio\n",
    "    )\n",
    "\n",
    "    if score >= 80:  # threshold for good match\n",
    "        matched_dates.append(post_to_date[match])\n",
    "        match_scores.append(score)\n",
    "    else:\n",
    "        matched_dates.append(None)\n",
    "        match_scores.append(score)\n",
    "\n",
    "\n",
    "classification_df[\"published_at\"] = matched_dates\n",
    "classification_df[\"match_score\"] = match_scores\n",
    "\n",
    "\n",
    "classification_df.to_csv(\"BLM_classification_with_dates_fuzzy.csv\", index=False)\n",
    "\n",
    "print(\"Matching complete. File saved: BLM_classification_with_dates_fuzzy.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned file saved. Rows: 7448\n"
     ]
    }
   ],
   "source": [
    "# Cleaning data\n",
    "df = pd.read_csv(\"BLM_classification_with_dates_fuzzy.csv\")\n",
    "\n",
    "# 1) Remove rows where \"published_at\" is empty (NaN or blank)\n",
    "df = df[df[\"published_at\"].notna()]\n",
    "df = df[df[\"published_at\"].astype(str).str.strip() != \"\"] \n",
    "\n",
    "# 2) Remove rows where \"dimension\" is \"0\"\n",
    "df = df[df[\"dimension\"] != 0]  \n",
    "df = df[df[\"dimension\"].astype(str).str.strip() != \"0\"]  \n",
    "\n",
    "# 3) Remove rows where \"confidence\" is \"unsure\"\n",
    "df = df[df[\"confidence\"].astype(str).str.strip().str.lower() != \"unsure\"]\n",
    " \n",
    "# 4) Remove unwanted columns by index \n",
    "df = df.drop(df.columns[[9, 10, 12]], axis=1)\n",
    "\n",
    "df.to_csv(\"BLM_classification_analysis_cleaned.csv\", index=False)\n",
    "\n",
    "print(f\"✅ Cleaned file saved. Rows: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
